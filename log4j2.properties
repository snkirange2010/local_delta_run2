# Root logger configuration
rootLogger.level = warn
rootLogger.appenderRef.stdout.ref = console

# Console appender configuration
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_OUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

# Suppress Spark verbose logging
logger.spark.name = org.apache.spark
logger.spark.level = warn

logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = warn

logger.delta.name = io.delta
logger.delta.level = info
```

---

## **Phase 5: Build Configuration**

### **Step 8: Configure IntelliJ IDEA for Scala**

1. **Install Scala Plugin** (if not already installed):
   - Go to **File → Settings → Plugins**
   - Search for "Scala"
   - Install **Scala** plugin by JetBrains
   - Restart IntelliJ

2. **Configure Scala SDK**:
   - Right-click on project → **Add Framework Support**
   - Check **Scala**
   - Select Scala version **2.12.15** (will download if needed)
   - Click **OK**

3. **Mark Directories**:
   - Right-click `src/main/scala` → **Mark Directory as → Sources Root**
   - Right-click `src/main/resources` → **Mark Directory as → Resources Root**
   - Right-click `src/test/scala` → **Mark Directory as → Test Sources Root**

### **Step 9: Import Maven Dependencies**

1. **Reload Maven Project**:
   - Open Maven tool window (View → Tool Windows → Maven)
   - Click **Reload All Maven Projects** (circular arrow icon)
   - Wait for dependencies to download (this may take 5-10 minutes)

2. **Verify Dependencies**:
   - Expand **Dependencies** in Maven window
   - Ensure all Spark, Delta, and Hadoop dependencies are loaded

---

## **Phase 6: Windows Environment Setup**

### **Step 10: Configure Windows Environment Variables**

1. **Set JAVA_HOME** (if not set):
```
   Variable: JAVA_HOME
   Value: C:\Program Files\Java\jdk-17
```

2. **Set SPARK_HOME**:
```
   Variable: SPARK_HOME
   Value: C:\spark-3.5.0-bin-hadoop3
```
   *(Adjust path to your Spark installation)*

3. **Set HADOOP_HOME**:
```
   Variable: HADOOP_HOME
   Value: C:\hadoop
```

4. **Download and Configure winutils.exe**:
   - Download `winutils.exe` for Hadoop 3.3.x from:
     https://github.com/cdarlint/winutils/tree/master/hadoop-3.3.1/bin
   - Create directory: `C:\hadoop\bin`
   - Place `winutils.exe` in `C:\hadoop\bin`
   - Add to PATH: `C:\hadoop\bin`

5. **Update PATH Variable**:
```
   Add: %SPARK_HOME%\bin
   Add: %HADOOP_HOME%\bin
   Add: %JAVA_HOME%\bin